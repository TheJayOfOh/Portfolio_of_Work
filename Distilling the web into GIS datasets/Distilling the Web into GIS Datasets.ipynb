{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this assignment, I will be taking this website (Top 10 Amusement Parks), \n",
    "# and extracting data to create both a point file that contains the locations of these food trucks throughout the week\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "# SETUP FOR ALL SECTIONS #\n",
    "import urllib2\n",
    "import lxml.html\n",
    "import os\n",
    "import sys\n",
    "import ggeocoder\n",
    "import csv\n",
    "from subprocess import call\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\bin')\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\arcpy')\n",
    "sys.path.append('C:\\\\Program Files (x86)\\\\ArcGIS\\\\Desktop10.3\\\\ArcToolbox\\\\Scripts')\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "env.overwriteOutput = True\n",
    "env.workspace = r\"C:\\Users\\osterj\\Desktop\\temp\"\n",
    "os.environ[\"GDAL_DATA\"] = \"C:\\\\OSGeo4W\\\\share\\\\gdal\"\n",
    "os.environ[\"GDAL_DRIVER_PATH\"] = \"C:\\\\OSGeo4W\\\\bin\\\\gdalplugins\"\n",
    "os.environ[\"PROJ_LIB\"] = \"C:\\\\OSGeo4W\\\\share\\\\proj\"\n",
    "os.environ[\"PATH\"] = \"C:\\\\OSGeo4W\\\\bin;\"+os.environ[\"PATH\"]+\";C:\\\\OSGeo4W\\\\apps\\\\msys\\\\bin;C:\\\\OSGeo4W\\\\apps\\\\Python27\\\\Scripts\"\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "def page_getter(url):\n",
    "    html = urllib2.urlopen(url).read()\n",
    "    dom = lxml.html.fromstring(html)\n",
    "    dom.make_links_absolute(url)\n",
    "    return dom\n",
    "\n",
    "website = r\"http://www.travelchannel.com/interests/family/articles/top-10-amusement-parks\"\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "dom = page_getter(website) \n",
    "parks = dom.cssselect(\".poi-title a\")     \n",
    "park_url_list = [link.attrib['href'] for link in parks]\n",
    "pnl = [link.text for link in parks]\n",
    "park_name_list = []\n",
    "\n",
    "# park name list is returning \"\\nPARKNAME\" so I need to delete the \\n\n",
    "for name in pnl:\n",
    "    park_name_list.append(name.splitlines()[1])\n",
    "# splitlines is a list that = [' ', 'PARKNAME'], so splitlines()[1] takes index 1 of the splitlines list, aka PARKNAME. \n",
    "    \n",
    "# makes a list of the park names with underscores where there are spaces\n",
    "underscore = []    \n",
    "for name in park_name_list:\n",
    "    new_name = \"\"\n",
    "    for char in name:        \n",
    "        if char == ' ' or char == '\\'':\n",
    "            char = '_'\n",
    "        new_name += char\n",
    "    underscore.append(new_name)    \n",
    "# print underscore\n",
    "\n",
    "# make a list of the full city addresses\n",
    "streets = dom.cssselect(\".street-address\")\n",
    "streets_list = [addr.text for addr in streets]\n",
    "# print streets_list\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# This next Section I'll be breaking up the full city address into its individual components\n",
    "# make a list of the cities\n",
    "cities_full = dom.cssselect(\".city\")\n",
    "city_list_full = [city.text for city in cities_full]\n",
    "# print city_list_full\n",
    "\n",
    "# cities_full contains city name COMMA state code SPACE zip code SPACE US, \n",
    "# so I should be able to take each string working backwards to make lists of \n",
    "# the country, then zip, then state, then city name\n",
    "# hopefully this for loop can make all 4 lists in 1 go\n",
    "cities = []\n",
    "states = []\n",
    "zips = []\n",
    "countries = []\n",
    "for city in city_list_full:\n",
    "    citye = \"\"\n",
    "    statee = \"\"\n",
    "    zipe = \"\"\n",
    "    countrye = \"\"\n",
    "    currLen = 0\n",
    "    len_city = len(city)\n",
    "    # example: SU 07844 HO ,yksudnaS\n",
    "    # example: countrye, zipe, statee, citye\n",
    "    for char in reversed(city):\n",
    "        if currLen < 2:\n",
    "            countrye = char + countrye\n",
    "            currLen += 1\n",
    "        elif currLen == 2:\n",
    "            currLen += 1\n",
    "        elif currLen < 8:\n",
    "            zipe = char + zipe\n",
    "            currLen += 1\n",
    "        elif currLen == 8:\n",
    "            currLen += 1\n",
    "        elif currLen < 11:\n",
    "            statee = char + statee\n",
    "            currLen += 1\n",
    "        elif currLen == 11 or currLen == 12:\n",
    "            currLen += 1\n",
    "        elif currLen > 12 and currLen < len_city:\n",
    "            citye = char + citye\n",
    "            currLen += 1\n",
    "        else:\n",
    "            pass\n",
    "    countries.append(countrye)\n",
    "    zips.append(zipe)\n",
    "    states.append(statee)\n",
    "    cities.append(citye)\n",
    "\n",
    "# make list of full addresses\n",
    "full_add = []\n",
    "strt = 0\n",
    "for park in park_name_list:\n",
    "    full_add.append(streets_list[strt] + \", \" + \n",
    "                    cities[strt] + \", \" +\n",
    "                    states[strt] + \", \" + \n",
    "                    zips[strt] + \", \" + \n",
    "                    countries[strt])\n",
    "    strt += 1\n",
    "\n",
    "# print countries\n",
    "# print zips\n",
    "# print states\n",
    "# print cities\n",
    "# print full_add\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# To clarify my code at this point, this is a list of all the lists I have at this point:\n",
    "\n",
    "# underscore       = park names with underscores where there are \"'\"s and \" \"s\n",
    "# park_url_list    = park URLs\n",
    "# pnl              = park names with \"\\n\" at the beginning of each park name\n",
    "# park_name_list   = park names \"properly\" written out\n",
    "# streets_list     = park street addresses\n",
    "# cities           = city the park is located in \n",
    "# states           = state the park is located in\n",
    "# zips             = zip code of the park\n",
    "# countries        = country of the park (they are all US in this case)\n",
    "# city_list_full   = park city, state, zip, and country combined into 1 line (ex. Sandusky, OH 44870 US )\n",
    "# full_add         = full address of the park, delineated with commas\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #\n",
    "\n",
    "# for park_info in underscore:\n",
    "#     print park_info\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------ #  \n",
    "\n",
    "# This section will be about getting these dictionaries and geocoding them\n",
    "new_full_add = []\n",
    "coordinates = []\n",
    "g = ggeocoder.Geocoder()\n",
    "for add in full_add:\n",
    "    results = g.geocode(add)\n",
    "    i = results[0]\n",
    "    new_full_add.append(i.formatted_address)\n",
    "    coordinates.append(i.coordinates)\n",
    "    \n",
    "# from the coordinates, separate latitudes from longitudes and put them into their own lists\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "for c in coordinates:\n",
    "    latitudes.append(c[0])\n",
    "    longitudes.append(c[1])\n",
    "\n",
    "# print latitudes\n",
    "# print longitudes\n",
    "    \n",
    "# print new_full_add\n",
    "# print coordinates\n",
    "\n",
    "# make a dictionary named each theme park name, and put in the name, street address, state, zip, country\n",
    "# and the full addresses as found by the geocoder as well as the coordinates\n",
    "start = 0\n",
    "for name in underscore:\n",
    "    underscore[start] = {\"Name\" : park_name_list[start], \n",
    "                         \"Address\" : streets_list[start], \n",
    "                         \"City\" : cities[start], \n",
    "                         \"State\" : states[start], \n",
    "                         \"Zip Code\" : zips[start],\n",
    "                         \"Country\" : countries[start],\n",
    "                         \"URL\" : park_url_list[start],\n",
    "                         \"Full Address\" : new_full_add[start],\n",
    "                         \"Latitude\" : latitudes[start],\n",
    "                         \"Longitude\" : longitudes[start]}\n",
    "    # print str(underscore[start])\n",
    "    start += 1  \n",
    "\n",
    "# print underscore        \n",
    "# Underscore is now a list of dictionaries containing all the relevant information\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ #  \n",
    "\n",
    "# converting this \"lovely\" list of dictionaries into a CSV file\n",
    "\n",
    "field_names = ['City', 'State', 'Full Address', 'Name', 'Address', 'URL', 'Country', 'Zip Code', 'Latitude', 'Longitude']\n",
    "test_file = open(r\"C:\\Users\\osterj\\Desktop\\temp\\themeparks.csv\",'wb')\n",
    "csvwriter = csv.DictWriter(test_file, delimiter = ',', fieldnames = field_names)\n",
    "csvwriter.writerow(dict((fn,fn) for fn in field_names))\n",
    "for row in underscore:\n",
    "     csvwriter.writerow(row)\n",
    "test_file.close()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------ # \n",
    "\n",
    "# make the shape file by making an xy event layer and copying it over to a .shp\n",
    "# GCS_WGS_1984 is the projection of this shp file, the datum is D_WGS_1984\n",
    "xy_layer = arcpy.MakeXYEventLayer_management(r\"C:\\Users\\osterj\\Desktop\\temp\\themeparks.csv\", \"Longitude\", \"Latitude\", \"theme_parks\")\n",
    "arcpy.CopyFeatures_management(xy_layer, r\"C:\\Users\\osterj\\Desktop\\temp\\themeparks.shp\")\n",
    "\n",
    "call(['C:\\\\OSGeo4W\\\\bin\\\\ogr2ogr',\n",
    "      '-f','GeoJSON','-t_srs','WGS84',\n",
    "      '-s_srs','WGS84',\n",
    "      r\"C:\\Users\\osterj\\Desktop\\temp\\themeparks.geojson\",\n",
    "      r\"C:\\Users\\osterj\\Desktop\\temp\\themeparks.shp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README NOTES:\n",
    "## Requirements:\n",
    "1. For people who don't go go theme parks all that often, I suppose this project would be fairly intellectually significant. Otherwise I'm not really sure how this project was intellectually significant other than for me to learn how to scrap data off of a website and turn it into spatial data. \n",
    "\n",
    "2. There were definitely plenty of challenges in this project, from trying to figure out how to select loose text within an html tag (the a-tag for this particular project) was one problem I ran into at the very beginning. The mid section of this project went a lot smoother, as it was mostly just taking the data I had already pulled down through the scraper and converting it into a multiple of lists. One interesting solution I found involved the city address line, as it contained the city name, the state, zip code, and country of the theme park, but it didn't delineate them the same way and it was in an odd order. There was no decent way to separate the data; however since the codes for country, zip, and state were all of the same length, I decided to have the code read that line backwards (to account for the varying length of the city names) and reconstruct each segment by appending character by character to the front of a new string from which I could append into lists. \n",
    "\n",
    "3. The biggest challenge was figuring out how to convert my list of dictionaries into a CSV, and then from a CSV to a SHP. This is where William Chan helped me out immensely, as he was a bit ahead of me in the process, he had found some pitfalls in the process and helped guide me through the steps I needed to take. Luckily though I remembered the ogr2ogr function from the first lab in this class so it was fairly easy to go back and readjust to fit this project. And luckily the .shp file creation in this project was already in the WGS84 projection so I didn't have to try and figure out what project to convert from.\n",
    "\n",
    "4. I managed to put this entire code together from beginning to end on 02/17/2016, I believe in total it took me about 6 hours, give or take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
